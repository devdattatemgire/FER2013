{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06fe94d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.wrappers.scikit_learn import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2d53b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the path to the train and test folders\n",
    "train_folder = r'C:\\Users\\devdatta\\OneDrive\\Documents\\Datasets\\facial_expr\\train'\n",
    "test_folder = r'C:\\Users\\devdatta\\OneDrive\\Documents\\Datasets\\facial_expr\\test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba2476ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to load images and labels from a folder\n",
    "def load_images_from_folder(folder):\n",
    "    images = []\n",
    "    labels = []\n",
    "    label_map = {'angry': 0, 'disgust': 1, 'fear': 2, 'happy': 3, 'neutral': 4, 'sad': 5, 'surprise': 6}\n",
    "    \n",
    "    for emotion_folder in os.listdir(folder):\n",
    "        label = label_map[emotion_folder]\n",
    "        emotion_path = os.path.join(folder, emotion_folder)\n",
    "        \n",
    "        for filename in os.listdir(emotion_path):\n",
    "            img_path = os.path.join(emotion_path, filename)\n",
    "            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)  # Read image in grayscale\n",
    "            if img is not None:\n",
    "                images.append(img)\n",
    "                labels.append(label)\n",
    "    \n",
    "    return np.array(images), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67d6cf92",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load images and labels\n",
    "images, labels = load_images_from_folder(train_folder)\n",
    "\n",
    "# One-hot encode the labels\n",
    "num_classes = 7\n",
    "labels = to_categorical(labels, num_classes)\n",
    "\n",
    "# Split data into train and validation sets\n",
    "train_images, val_images, train_labels, val_labels = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Preprocess the data (normalize)\n",
    "train_images = train_images / 255.0\n",
    "val_images = val_images / 255.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78128134",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CNN model\n",
    "model = Sequential()\n",
    "\n",
    "# Add three convolutional layers with max pooling and dropout\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(48, 48, 1)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# Flatten the output to be fed into the fully connected layers\n",
    "model.add(Flatten())\n",
    "\n",
    "# Add two fully connected layers with dropout\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11276d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Learning rate scheduling\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=1e-6)\n",
    "\n",
    "# Early stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8bcb43fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 46, 46, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 23, 23, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 23, 23, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 21, 21, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 10, 10, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 10, 10, 64)        0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 8, 8, 128)         73856     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 4, 4, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 4, 4, 128)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2048)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               524544    \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 7)                 1799      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 619,015\n",
      "Trainable params: 619,015\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Print the model summary (optional)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4fac207d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "359/359 [==============================] - 47s 127ms/step - loss: 1.8375 - accuracy: 0.2387 - val_loss: 1.8663 - val_accuracy: 0.2567 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "359/359 [==============================] - 45s 126ms/step - loss: 1.8177 - accuracy: 0.2477 - val_loss: 1.8373 - val_accuracy: 0.2621 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "359/359 [==============================] - 46s 127ms/step - loss: 1.7798 - accuracy: 0.2619 - val_loss: 1.7833 - val_accuracy: 0.3065 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "359/359 [==============================] - 51s 142ms/step - loss: 1.7313 - accuracy: 0.2991 - val_loss: 1.7036 - val_accuracy: 0.3551 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "359/359 [==============================] - 55s 154ms/step - loss: 1.6782 - accuracy: 0.3343 - val_loss: 1.6443 - val_accuracy: 0.3750 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "359/359 [==============================] - 52s 146ms/step - loss: 1.6349 - accuracy: 0.3601 - val_loss: 1.6022 - val_accuracy: 0.3972 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "359/359 [==============================] - 58s 163ms/step - loss: 1.6029 - accuracy: 0.3767 - val_loss: 1.5697 - val_accuracy: 0.4105 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "359/359 [==============================] - 59s 165ms/step - loss: 1.5793 - accuracy: 0.3903 - val_loss: 1.5583 - val_accuracy: 0.4101 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "359/359 [==============================] - 57s 160ms/step - loss: 1.5559 - accuracy: 0.3953 - val_loss: 1.5203 - val_accuracy: 0.4234 - lr: 1.0000e-04\n",
      "Epoch 10/100\n",
      "359/359 [==============================] - 54s 150ms/step - loss: 1.5306 - accuracy: 0.4099 - val_loss: 1.5013 - val_accuracy: 0.4340 - lr: 1.0000e-04\n",
      "Epoch 11/100\n",
      "359/359 [==============================] - 52s 145ms/step - loss: 1.5124 - accuracy: 0.4176 - val_loss: 1.4750 - val_accuracy: 0.4462 - lr: 1.0000e-04\n",
      "Epoch 12/100\n",
      "359/359 [==============================] - 54s 150ms/step - loss: 1.4915 - accuracy: 0.4261 - val_loss: 1.4639 - val_accuracy: 0.4497 - lr: 1.0000e-04\n",
      "Epoch 13/100\n",
      "359/359 [==============================] - 53s 149ms/step - loss: 1.4739 - accuracy: 0.4343 - val_loss: 1.4432 - val_accuracy: 0.4556 - lr: 1.0000e-04\n",
      "Epoch 14/100\n",
      "359/359 [==============================] - 53s 149ms/step - loss: 1.4536 - accuracy: 0.4430 - val_loss: 1.4188 - val_accuracy: 0.4638 - lr: 1.0000e-04\n",
      "Epoch 15/100\n",
      "359/359 [==============================] - 54s 152ms/step - loss: 1.4365 - accuracy: 0.4512 - val_loss: 1.4011 - val_accuracy: 0.4730 - lr: 1.0000e-04\n",
      "Epoch 16/100\n",
      "359/359 [==============================] - 55s 152ms/step - loss: 1.4150 - accuracy: 0.4591 - val_loss: 1.3854 - val_accuracy: 0.4739 - lr: 1.0000e-04\n",
      "Epoch 17/100\n",
      "359/359 [==============================] - 55s 154ms/step - loss: 1.4018 - accuracy: 0.4675 - val_loss: 1.3746 - val_accuracy: 0.4801 - lr: 1.0000e-04\n",
      "Epoch 18/100\n",
      "359/359 [==============================] - 53s 149ms/step - loss: 1.3831 - accuracy: 0.4749 - val_loss: 1.3589 - val_accuracy: 0.4829 - lr: 1.0000e-04\n",
      "Epoch 19/100\n",
      "359/359 [==============================] - 53s 148ms/step - loss: 1.3685 - accuracy: 0.4786 - val_loss: 1.3442 - val_accuracy: 0.4885 - lr: 1.0000e-04\n",
      "Epoch 20/100\n",
      "359/359 [==============================] - 53s 148ms/step - loss: 1.3526 - accuracy: 0.4856 - val_loss: 1.3365 - val_accuracy: 0.4899 - lr: 1.0000e-04\n",
      "Epoch 21/100\n",
      "359/359 [==============================] - 56s 157ms/step - loss: 1.3420 - accuracy: 0.4898 - val_loss: 1.3219 - val_accuracy: 0.4972 - lr: 1.0000e-04\n",
      "Epoch 22/100\n",
      "359/359 [==============================] - 53s 148ms/step - loss: 1.3292 - accuracy: 0.4946 - val_loss: 1.3176 - val_accuracy: 0.4984 - lr: 1.0000e-04\n",
      "Epoch 23/100\n",
      "359/359 [==============================] - 52s 146ms/step - loss: 1.3252 - accuracy: 0.4965 - val_loss: 1.3051 - val_accuracy: 0.4993 - lr: 1.0000e-04\n",
      "Epoch 24/100\n",
      "359/359 [==============================] - 53s 147ms/step - loss: 1.3057 - accuracy: 0.5029 - val_loss: 1.2981 - val_accuracy: 0.5042 - lr: 1.0000e-04\n",
      "Epoch 25/100\n",
      "359/359 [==============================] - 52s 144ms/step - loss: 1.3001 - accuracy: 0.5102 - val_loss: 1.2877 - val_accuracy: 0.5108 - lr: 1.0000e-04\n",
      "Epoch 26/100\n",
      "359/359 [==============================] - 52s 145ms/step - loss: 1.2864 - accuracy: 0.5129 - val_loss: 1.2850 - val_accuracy: 0.5164 - lr: 1.0000e-04\n",
      "Epoch 27/100\n",
      "359/359 [==============================] - 52s 145ms/step - loss: 1.2780 - accuracy: 0.5135 - val_loss: 1.2661 - val_accuracy: 0.5162 - lr: 1.0000e-04\n",
      "Epoch 28/100\n",
      "359/359 [==============================] - 52s 146ms/step - loss: 1.2704 - accuracy: 0.5169 - val_loss: 1.2663 - val_accuracy: 0.5193 - lr: 1.0000e-04\n",
      "Epoch 29/100\n",
      "359/359 [==============================] - 52s 146ms/step - loss: 1.2601 - accuracy: 0.5230 - val_loss: 1.2554 - val_accuracy: 0.5232 - lr: 1.0000e-04\n",
      "Epoch 30/100\n",
      "359/359 [==============================] - 52s 146ms/step - loss: 1.2493 - accuracy: 0.5297 - val_loss: 1.2475 - val_accuracy: 0.5237 - lr: 1.0000e-04\n",
      "Epoch 31/100\n",
      "359/359 [==============================] - 52s 146ms/step - loss: 1.2420 - accuracy: 0.5315 - val_loss: 1.2445 - val_accuracy: 0.5303 - lr: 1.0000e-04\n",
      "Epoch 32/100\n",
      "359/359 [==============================] - 56s 155ms/step - loss: 1.2346 - accuracy: 0.5325 - val_loss: 1.2482 - val_accuracy: 0.5354 - lr: 1.0000e-04\n",
      "Epoch 33/100\n",
      "359/359 [==============================] - 54s 151ms/step - loss: 1.2230 - accuracy: 0.5369 - val_loss: 1.2298 - val_accuracy: 0.5343 - lr: 1.0000e-04\n",
      "Epoch 34/100\n",
      "359/359 [==============================] - 57s 158ms/step - loss: 1.2130 - accuracy: 0.5429 - val_loss: 1.2299 - val_accuracy: 0.5380 - lr: 1.0000e-04\n",
      "Epoch 35/100\n",
      "359/359 [==============================] - 56s 156ms/step - loss: 1.2088 - accuracy: 0.5449 - val_loss: 1.2198 - val_accuracy: 0.5401 - lr: 1.0000e-04\n",
      "Epoch 36/100\n",
      "359/359 [==============================] - 58s 163ms/step - loss: 1.2040 - accuracy: 0.5460 - val_loss: 1.2251 - val_accuracy: 0.5364 - lr: 1.0000e-04\n",
      "Epoch 37/100\n",
      "359/359 [==============================] - 57s 157ms/step - loss: 1.1967 - accuracy: 0.5501 - val_loss: 1.2120 - val_accuracy: 0.5435 - lr: 1.0000e-04\n",
      "Epoch 38/100\n",
      "359/359 [==============================] - 57s 160ms/step - loss: 1.1834 - accuracy: 0.5570 - val_loss: 1.2094 - val_accuracy: 0.5428 - lr: 1.0000e-04\n",
      "Epoch 39/100\n",
      "359/359 [==============================] - 58s 162ms/step - loss: 1.1802 - accuracy: 0.5544 - val_loss: 1.2071 - val_accuracy: 0.5465 - lr: 1.0000e-04\n",
      "Epoch 40/100\n",
      "359/359 [==============================] - 57s 159ms/step - loss: 1.1695 - accuracy: 0.5597 - val_loss: 1.2030 - val_accuracy: 0.5507 - lr: 1.0000e-04\n",
      "Epoch 41/100\n",
      "359/359 [==============================] - 58s 162ms/step - loss: 1.1673 - accuracy: 0.5627 - val_loss: 1.2004 - val_accuracy: 0.5566 - lr: 1.0000e-04\n",
      "Epoch 42/100\n",
      "359/359 [==============================] - 58s 162ms/step - loss: 1.1556 - accuracy: 0.5668 - val_loss: 1.2002 - val_accuracy: 0.5495 - lr: 1.0000e-04\n",
      "Epoch 43/100\n",
      "359/359 [==============================] - 64s 177ms/step - loss: 1.1439 - accuracy: 0.5720 - val_loss: 1.1890 - val_accuracy: 0.5524 - lr: 1.0000e-04\n",
      "Epoch 44/100\n",
      "359/359 [==============================] - 61s 169ms/step - loss: 1.1472 - accuracy: 0.5706 - val_loss: 1.1911 - val_accuracy: 0.5549 - lr: 1.0000e-04\n",
      "Epoch 45/100\n",
      "359/359 [==============================] - 53s 148ms/step - loss: 1.1314 - accuracy: 0.5752 - val_loss: 1.1859 - val_accuracy: 0.5540 - lr: 1.0000e-04\n",
      "Epoch 46/100\n",
      "359/359 [==============================] - 53s 148ms/step - loss: 1.1308 - accuracy: 0.5764 - val_loss: 1.1815 - val_accuracy: 0.5594 - lr: 1.0000e-04\n",
      "Epoch 47/100\n",
      "359/359 [==============================] - 54s 149ms/step - loss: 1.1220 - accuracy: 0.5808 - val_loss: 1.1754 - val_accuracy: 0.5569 - lr: 1.0000e-04\n",
      "Epoch 48/100\n",
      "359/359 [==============================] - 53s 148ms/step - loss: 1.1154 - accuracy: 0.5835 - val_loss: 1.1767 - val_accuracy: 0.5578 - lr: 1.0000e-04\n",
      "Epoch 49/100\n",
      "359/359 [==============================] - 53s 148ms/step - loss: 1.1106 - accuracy: 0.5856 - val_loss: 1.1700 - val_accuracy: 0.5655 - lr: 1.0000e-04\n",
      "Epoch 50/100\n",
      "359/359 [==============================] - 53s 147ms/step - loss: 1.1040 - accuracy: 0.5872 - val_loss: 1.1720 - val_accuracy: 0.5610 - lr: 1.0000e-04\n",
      "Epoch 51/100\n",
      "359/359 [==============================] - 52s 144ms/step - loss: 1.0992 - accuracy: 0.5897 - val_loss: 1.1681 - val_accuracy: 0.5646 - lr: 1.0000e-04\n",
      "Epoch 52/100\n",
      "359/359 [==============================] - 52s 145ms/step - loss: 1.0911 - accuracy: 0.5918 - val_loss: 1.1674 - val_accuracy: 0.5653 - lr: 1.0000e-04\n",
      "Epoch 53/100\n",
      "359/359 [==============================] - 52s 145ms/step - loss: 1.0830 - accuracy: 0.5966 - val_loss: 1.1604 - val_accuracy: 0.5657 - lr: 1.0000e-04\n",
      "Epoch 54/100\n",
      "359/359 [==============================] - 52s 144ms/step - loss: 1.0786 - accuracy: 0.5952 - val_loss: 1.1576 - val_accuracy: 0.5662 - lr: 1.0000e-04\n",
      "Epoch 55/100\n",
      "359/359 [==============================] - 52s 144ms/step - loss: 1.0731 - accuracy: 0.5992 - val_loss: 1.1667 - val_accuracy: 0.5679 - lr: 1.0000e-04\n",
      "Epoch 56/100\n",
      "359/359 [==============================] - 52s 145ms/step - loss: 1.0709 - accuracy: 0.5985 - val_loss: 1.1502 - val_accuracy: 0.5690 - lr: 1.0000e-04\n",
      "Epoch 57/100\n",
      "359/359 [==============================] - 53s 147ms/step - loss: 1.0617 - accuracy: 0.6034 - val_loss: 1.1540 - val_accuracy: 0.5702 - lr: 1.0000e-04\n",
      "Epoch 58/100\n",
      "359/359 [==============================] - 53s 147ms/step - loss: 1.0509 - accuracy: 0.6053 - val_loss: 1.1491 - val_accuracy: 0.5726 - lr: 1.0000e-04\n",
      "Epoch 59/100\n",
      "359/359 [==============================] - 52s 146ms/step - loss: 1.0506 - accuracy: 0.6109 - val_loss: 1.1492 - val_accuracy: 0.5721 - lr: 1.0000e-04\n",
      "Epoch 60/100\n",
      "359/359 [==============================] - 53s 147ms/step - loss: 1.0452 - accuracy: 0.6119 - val_loss: 1.1498 - val_accuracy: 0.5709 - lr: 1.0000e-04\n",
      "Epoch 61/100\n",
      "359/359 [==============================] - 53s 147ms/step - loss: 1.0355 - accuracy: 0.6118 - val_loss: 1.1458 - val_accuracy: 0.5756 - lr: 1.0000e-04\n",
      "Epoch 62/100\n",
      "359/359 [==============================] - 53s 146ms/step - loss: 1.0322 - accuracy: 0.6136 - val_loss: 1.1403 - val_accuracy: 0.5766 - lr: 1.0000e-04\n",
      "Epoch 63/100\n",
      "359/359 [==============================] - 53s 146ms/step - loss: 1.0272 - accuracy: 0.6166 - val_loss: 1.1471 - val_accuracy: 0.5711 - lr: 1.0000e-04\n",
      "Epoch 64/100\n",
      "359/359 [==============================] - 53s 146ms/step - loss: 1.0203 - accuracy: 0.6208 - val_loss: 1.1382 - val_accuracy: 0.5775 - lr: 1.0000e-04\n",
      "Epoch 65/100\n",
      "359/359 [==============================] - 61s 170ms/step - loss: 1.0153 - accuracy: 0.6221 - val_loss: 1.1390 - val_accuracy: 0.5803 - lr: 1.0000e-04\n",
      "Epoch 66/100\n",
      "359/359 [==============================] - 52s 146ms/step - loss: 1.0112 - accuracy: 0.6222 - val_loss: 1.1364 - val_accuracy: 0.5780 - lr: 1.0000e-04\n",
      "Epoch 67/100\n",
      "359/359 [==============================] - 54s 151ms/step - loss: 1.0055 - accuracy: 0.6247 - val_loss: 1.1361 - val_accuracy: 0.5747 - lr: 1.0000e-04\n",
      "Epoch 68/100\n",
      "359/359 [==============================] - 54s 150ms/step - loss: 1.0033 - accuracy: 0.6272 - val_loss: 1.1388 - val_accuracy: 0.5792 - lr: 1.0000e-04\n",
      "Epoch 69/100\n",
      "359/359 [==============================] - 54s 151ms/step - loss: 0.9911 - accuracy: 0.6308 - val_loss: 1.1325 - val_accuracy: 0.5819 - lr: 1.0000e-04\n",
      "Epoch 70/100\n",
      "359/359 [==============================] - 53s 149ms/step - loss: 0.9828 - accuracy: 0.6339 - val_loss: 1.1372 - val_accuracy: 0.5773 - lr: 1.0000e-04\n",
      "Epoch 71/100\n",
      "359/359 [==============================] - 53s 147ms/step - loss: 0.9765 - accuracy: 0.6390 - val_loss: 1.1340 - val_accuracy: 0.5812 - lr: 1.0000e-04\n",
      "Epoch 72/100\n",
      "359/359 [==============================] - 53s 148ms/step - loss: 0.9726 - accuracy: 0.6370 - val_loss: 1.1331 - val_accuracy: 0.5805 - lr: 1.0000e-04\n",
      "Epoch 73/100\n",
      "359/359 [==============================] - 53s 148ms/step - loss: 0.9733 - accuracy: 0.6371 - val_loss: 1.1362 - val_accuracy: 0.5744 - lr: 1.0000e-04\n",
      "Epoch 74/100\n",
      "359/359 [==============================] - 53s 147ms/step - loss: 0.9695 - accuracy: 0.6390 - val_loss: 1.1276 - val_accuracy: 0.5839 - lr: 1.0000e-04\n",
      "Epoch 75/100\n",
      "359/359 [==============================] - 53s 148ms/step - loss: 0.9597 - accuracy: 0.6408 - val_loss: 1.1202 - val_accuracy: 0.5841 - lr: 1.0000e-04\n",
      "Epoch 76/100\n",
      "359/359 [==============================] - 53s 148ms/step - loss: 0.9482 - accuracy: 0.6465 - val_loss: 1.1241 - val_accuracy: 0.5832 - lr: 1.0000e-04\n",
      "Epoch 77/100\n",
      "359/359 [==============================] - 52s 146ms/step - loss: 0.9515 - accuracy: 0.6426 - val_loss: 1.1305 - val_accuracy: 0.5810 - lr: 1.0000e-04\n",
      "Epoch 78/100\n",
      "359/359 [==============================] - 53s 147ms/step - loss: 0.9419 - accuracy: 0.6496 - val_loss: 1.1312 - val_accuracy: 0.5815 - lr: 1.0000e-04\n",
      "Epoch 79/100\n",
      "359/359 [==============================] - 52s 145ms/step - loss: 0.9393 - accuracy: 0.6499 - val_loss: 1.1261 - val_accuracy: 0.5825 - lr: 1.0000e-04\n",
      "Epoch 80/100\n",
      "359/359 [==============================] - 52s 146ms/step - loss: 0.9390 - accuracy: 0.6529 - val_loss: 1.1193 - val_accuracy: 0.5848 - lr: 1.0000e-04\n",
      "Epoch 81/100\n",
      "359/359 [==============================] - 53s 146ms/step - loss: 0.9362 - accuracy: 0.6503 - val_loss: 1.1237 - val_accuracy: 0.5886 - lr: 1.0000e-04\n",
      "Epoch 82/100\n",
      "359/359 [==============================] - 52s 146ms/step - loss: 0.9244 - accuracy: 0.6546 - val_loss: 1.1174 - val_accuracy: 0.5914 - lr: 1.0000e-04\n",
      "Epoch 83/100\n",
      "359/359 [==============================] - 53s 146ms/step - loss: 0.9157 - accuracy: 0.6605 - val_loss: 1.1255 - val_accuracy: 0.5839 - lr: 1.0000e-04\n",
      "Epoch 84/100\n",
      "359/359 [==============================] - 52s 146ms/step - loss: 0.9111 - accuracy: 0.6619 - val_loss: 1.1159 - val_accuracy: 0.5897 - lr: 1.0000e-04\n",
      "Epoch 85/100\n",
      "359/359 [==============================] - 52s 145ms/step - loss: 0.9101 - accuracy: 0.6660 - val_loss: 1.1229 - val_accuracy: 0.5873 - lr: 1.0000e-04\n",
      "Epoch 86/100\n",
      "359/359 [==============================] - 52s 145ms/step - loss: 0.9047 - accuracy: 0.6660 - val_loss: 1.1226 - val_accuracy: 0.5864 - lr: 1.0000e-04\n",
      "Epoch 87/100\n",
      "359/359 [==============================] - 52s 146ms/step - loss: 0.8970 - accuracy: 0.6700 - val_loss: 1.1203 - val_accuracy: 0.5883 - lr: 1.0000e-04\n",
      "Epoch 88/100\n",
      "359/359 [==============================] - 52s 145ms/step - loss: 0.8940 - accuracy: 0.6682 - val_loss: 1.1202 - val_accuracy: 0.5890 - lr: 1.0000e-04\n",
      "Epoch 89/100\n",
      "359/359 [==============================] - 53s 146ms/step - loss: 0.8849 - accuracy: 0.6710 - val_loss: 1.1179 - val_accuracy: 0.5862 - lr: 1.0000e-04\n",
      "Epoch 90/100\n",
      "359/359 [==============================] - 52s 145ms/step - loss: 0.8715 - accuracy: 0.6787 - val_loss: 1.1171 - val_accuracy: 0.5927 - lr: 2.0000e-05\n",
      "Epoch 91/100\n",
      "359/359 [==============================] - 52s 145ms/step - loss: 0.8693 - accuracy: 0.6791 - val_loss: 1.1178 - val_accuracy: 0.5927 - lr: 2.0000e-05\n",
      "Epoch 92/100\n",
      "359/359 [==============================] - 52s 145ms/step - loss: 0.8655 - accuracy: 0.6784 - val_loss: 1.1199 - val_accuracy: 0.5906 - lr: 2.0000e-05\n",
      "Epoch 93/100\n",
      "359/359 [==============================] - 52s 146ms/step - loss: 0.8618 - accuracy: 0.6810 - val_loss: 1.1231 - val_accuracy: 0.5909 - lr: 2.0000e-05\n",
      "Epoch 94/100\n",
      "359/359 [==============================] - 52s 146ms/step - loss: 0.8649 - accuracy: 0.6799 - val_loss: 1.1185 - val_accuracy: 0.5911 - lr: 2.0000e-05\n"
     ]
    }
   ],
   "source": [
    "# Train the model on the FER2013 dataset\n",
    "batch_size = 64\n",
    "epochs = 100  # Increase the number of epochs\n",
    "\n",
    "history = model.fit(train_images, train_labels,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    validation_data=(val_images, val_labels),\n",
    "                    callbacks=[reduce_lr, early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8885a1ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 1.094894289970398\n",
      "Test Accuracy: 0.5929228067398071\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Evaluate the model on the test dataset\n",
    "test_images, test_labels = load_images_from_folder(test_folder)\n",
    "test_images = test_images / 255.0\n",
    "test_labels = to_categorical(test_labels, num_classes)\n",
    "\n",
    "score = model.evaluate(test_images, test_labels, verbose=0)\n",
    "print(\"Test Loss:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2264a285",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
